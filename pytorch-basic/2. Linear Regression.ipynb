{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3ce4c28-4558-48b8-8cbc-45b091db29d7",
   "metadata": {},
   "source": [
    "# 선형 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2228981a-9353-4647-abb3-3ad25a287521",
   "metadata": {},
   "source": [
    "## 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e051cb1-1446-4e95-a97e-02ea098ad96b",
   "metadata": {},
   "source": [
    "train data와 test data\n",
    "- train data: 예측을 위해 학습에 사용하는 데이터셋\n",
    "- test data: 학습 완료 후 모델을 판별하기 위한 데이터셋\n",
    "\n",
    "모델을 학습하는 데 사용하는 데이터는 pytorch의 텐서 형태여야 합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61459f-9bed-4090-b6b3-ef3a825f0cd2",
   "metadata": {},
   "source": [
    "## 가설"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea94449-75e2-47ff-8608-cd9afbce6a43",
   "metadata": {},
   "source": [
    "머신러닝에서 임의로 추측해서 세워보거나 경험적으로 알고있는 식을 가설이라고 하고 이 가설이 틀리다고 판단되면 계속 수정해나간다\n",
    "\n",
    "선형 회귀의 가설:\n",
    "$y = Wx + b$\n",
    "\n",
    "- 이 때, $W$를 가중치, $b$를 편향이라고 함\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00033c09-294a-457d-9c49-f2362bc0c921",
   "metadata": {},
   "source": [
    "## 비용 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d41cbc-c3e2-4e6a-b90d-807c7c04f5fc",
   "metadata": {},
   "source": [
    "아래의 용어는 전부 같다\n",
    "- **비용 함수(cost function)**\n",
    "- **손실 함수(loss function)**\n",
    "- 오차 함수(error function)\n",
    "- 목적 함수(objective function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e263c-5b03-48be-ae65-7199515a735d",
   "metadata": {},
   "source": [
    "2차원 훈련 데이터들이 있고 이 데이터들을 가장 잘 표현하는 직선을 그리는 것이 목표라고 하면 직선과 데이터들의 차이가 생긴다.\n",
    "이를 오차라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60463269-8158-472c-b190-b7e080ae81ae",
   "metadata": {},
   "source": [
    "모든 훈련 데이터에 대해서 오차를 구하고 총 오차를 구하는 방법으로 모든 오차를 합하는 방법을 채택한다고 가정한다\n",
    "\n",
    "|실제값|예측값|오차|\n",
    "|--|--|--|\n",
    "|25|27|-2|\n",
    "|50|40|10|\n",
    "|42|53|-9|\n",
    "|61|66|-5|\n",
    "\n",
    "모든 오차를 더하면 음수와 양수의 값이 모두 존재하기 때문에 모든 오차가 포함되지 않게 된다.\n",
    "따라서 오차값을 모두 제곱하고 더하는 방법으로 오차를 구할 수 있는데 이를 평균 제곱 오차(Mean Squared Error, MSE)라고 한다.\n",
    "이를 함수로 정의해서 값을 최소가 되도록 하는 W와 b를 구하는 과정을 훈련이라고 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba36f52-4896-4e87-a48a-d25f07e0163a",
   "metadata": {},
   "source": [
    "## 옵티마이저\n",
    "\n",
    "- 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84637d9-ff7e-4ff1-9355-6141fce55862",
   "metadata": {},
   "source": [
    "비용 함수의 최솟값을 구하는 데 사용되는 것이 옵티마이저(Optimizer) 알고리즘이다. 최적화 알고리즘이라고도 불리는데 이 알고리즘을 통해 W와 b를 찾아내는 과정을 학습이라고 한다. 가장 기본적인 최적화 알고리즘으로 경사 하강법(Gradient Descent)이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39a2ad-a5a8-4934-bc55-1fe6175444cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
